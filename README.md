# Ollama-Local-Chat-Interface
> |
**Running the Streamlit application**

1. Clone repo: Run this in your terminal

       git clone https://github.com/TGouriSankar/Ollama-Local-Chat-Interface

2. Install Dependencies: Execute to install dependencies

       pip install -r req.txt

3. Launch the App: Run to start the Streamlit interface on localhost

       streamlit run chat_ui.py

> Apache-2.0 license
